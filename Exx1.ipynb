{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048c27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/hubertsimonbom/anaconda3/lib/python3.11/site-packages (4.11.0.86)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/hubertsimonbom/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2f98f",
   "metadata": {},
   "source": [
    "# Detecting and tracking moving cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe6de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cars: 16\n",
      "Cars per minute: 5.40\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "cap = cv2.VideoCapture('Traffic_Laramie_1.mp4')\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n",
    "roi_y1, roi_y2 = 250, 600  \n",
    "line_y = roi_y2 - 20  \n",
    "centroids_memory = []\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "car_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,0] + boxes[:,2]\n",
    "    y2 = boxes[:,1] + boxes[:,3]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = idxs[-1]\n",
    "        pick.append(last)\n",
    "        suppress = [last]\n",
    "\n",
    "        for i in idxs[:-1]:\n",
    "            xx1 = max(x1[last], x1[i])\n",
    "            yy1 = max(y1[last], y1[i])\n",
    "            xx2 = min(x2[last], x2[i])\n",
    "            yy2 = min(y2[last], y2[i])\n",
    "            w = max(0, xx2 - xx1 + 1)\n",
    "            h = max(0, yy2 - yy1 + 1)\n",
    "            overlap = float(w * h) / area[i]\n",
    "\n",
    "            if overlap > overlapThresh:\n",
    "                suppress.append(i)\n",
    "\n",
    "        idxs = np.delete(idxs, np.where(np.isin(idxs, suppress)))\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    roi = frame[roi_y1:roi_y2, :]\n",
    "    mask = fgbg.apply(roi)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = w / float(h)\n",
    "            if 1.2 < aspect_ratio < 4.0 and w > 40 and h > 20:\n",
    "                boxes.append((x, y, w, h))\n",
    "    merged_boxes = non_max_suppression_fast(boxes, overlapThresh=0.55)\n",
    "    new_centroids = []\n",
    "    for (x, y, w, h) in merged_boxes:\n",
    "        cx = x + w // 2\n",
    "        cy = y + h // 2 + roi_y1\n",
    "        new_centroids.append((cx, cy))\n",
    "\n",
    "        if (\n",
    "            cy >= roi_y2 - 50 or\n",
    "            cy <= roi_y1 + 50 or\n",
    "            cx <= 50 or\n",
    "            cx >= frame.shape[1] - 50\n",
    "        ):\n",
    "            if all(abs(cx - m[0]) > 50 or abs(cy - m[1]) > 30 for m in centroids_memory):\n",
    "                car_count += 1\n",
    "                centroids_memory.append((cx, cy))\n",
    "\n",
    "        cv2.rectangle(frame, (x, y + roi_y1), (x + w, y + h + roi_y1), (0, 255, 0), 2)\n",
    "\n",
    "    if len(centroids_memory) > 50:\n",
    "        centroids_memory = centroids_memory[-50:]\n",
    "\n",
    "    for i in range(0, frame.shape[1], 20):\n",
    "        if (i // 20) % 2 == 0:\n",
    "            cv2.line(frame, (i, roi_y1), (i + 10, roi_y1), (0, 0, 255), 2)\n",
    "            cv2.line(frame, (i, roi_y2), (i + 10, roi_y2), (0, 0, 255), 2)\n",
    "    cv2.line(frame, (0, roi_y1), (0, roi_y2), (0, 0, 255), 2)\n",
    "    cv2.line(frame, (frame.shape[1] - 1, roi_y1), (frame.shape[1] - 1, roi_y2), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    cv2.line(frame, (0, roi_y2), (frame.shape[1], roi_y2), (255, 0, 0), 2)  \n",
    "    cv2.line(frame, (0, roi_y1), (frame.shape[1], roi_y1), (255, 0, 0), 2)  \n",
    "    cv2.line(frame, (0, roi_y1), (0, roi_y2), (255, 0, 0), 2)               \n",
    "    cv2.line(frame, (frame.shape[1] - 1, roi_y1), (frame.shape[1] - 1, roi_y2), (255, 0, 0), 2)  \n",
    "\n",
    "    cv2.putText(frame, f\"Cars -> {car_count}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, \"Focus street\", (30, roi_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Full Frame with Detection', frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "duration_sec = frame_count / frame_rate\n",
    "cars_per_minute = car_count / (duration_sec / 60)\n",
    "print(f\"Total cars: {car_count}\")\n",
    "print(f\"Cars per minute: {cars_per_minute:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344e7b7",
   "metadata": {},
   "source": [
    "# Count the number of cars that go from the city downtown to the city centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96907376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cars: 3\n",
      "Cars per minute: 1.70\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = \"Traffic_Laramie_2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100)\n",
    "\n",
    "roi_y1, roi_y2 = 300, 460\n",
    "car_count = 0\n",
    "min_contour_area = 500\n",
    "line_position = 400  \n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "detected_centroids = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    roi = frame[roi_y1:roi_y2, :]\n",
    "    mask = fgbg.apply(roi)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < min_contour_area:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cx = x + w // 2\n",
    "        cv2.rectangle(roi, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.circle(roi, (cx, y + h // 2), 3, (0, 0, 255), -1)\n",
    "        detected_centroids.append(cx)\n",
    "\n",
    "        if cx > line_position - 5 and cx < line_position + 5:\n",
    "            car_count += 1\n",
    "            \n",
    "    cv2.line(roi, (line_position, 0), (line_position, roi.shape[0]), (255, 0, 0), 2)\n",
    "    cv2.putText(roi, f'Cars counted: {car_count}', (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    frame[roi_y1:roi_y2, :] = roi\n",
    "    cv2.imshow(\"Task 2 - Press Q to stop\", frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "duration_sec = frame_count / frame_rate\n",
    "cars_per_minute = car_count / (duration_sec / 60)\n",
    "print(f\"Total cars: {car_count}\")\n",
    "print(f\"Cars per minute: {cars_per_minute:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96395c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
